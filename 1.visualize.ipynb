{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702998c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "import torch\n",
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset\n",
    "from src.env.env import RILAB_OMY_ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4b34c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './dataset/demo_data'\n",
    "dataset = LeRobotDataset('Jeongeun/deep_learning_2025',root = root )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b982c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EpisodeSampler(torch.utils.data.Sampler):\n",
    "    \"\"\"\n",
    "    Sampler for a single episode\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset: LeRobotDataset, episode_index: int):\n",
    "        from_idx = dataset.episode_data_index[\"from\"][episode_index].item()\n",
    "        to_idx = dataset.episode_data_index[\"to\"][episode_index].item()\n",
    "        self.frame_ids = range(from_idx, to_idx)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.frame_ids)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.frame_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef9d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an episode index that you want to visualize\n",
    "episode_index =1\n",
    "\n",
    "episode_sampler = EpisodeSampler(dataset, episode_index)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=1,\n",
    "    batch_size=1,\n",
    "    sampler=episode_sampler,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52a9f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iter_dataloader = iter(dataloader)\n",
    "data = next(iter_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fb3bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config_file_path = data['config_file_name'][0]\n",
    "except: config_file_path = 'configs/train2.json'\n",
    "with open(config_file_path) as f:\n",
    "    env_conf = json.load(f)\n",
    "omy_env = RILAB_OMY_ENV(cfg=env_conf, seed=0, action_type='joint', vis_mode = 'teleop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c620c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geom_idx = omy_env.env.geom_names.index('box_1_geom')\n",
    "# omy_env.env.model.geom(geom_idx).rgba = np.array([0.5, 1.0, 1.0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ebf040",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "iter_dataloader = iter(dataloader)\n",
    "omy_env.reset()\n",
    "action = omy_env.get_full_joint_state()\n",
    "clips = []\n",
    "actions = []\n",
    "save_flag = True\n",
    "while omy_env.env.is_viewer_alive():\n",
    "    # PnPEnv.forward_env(action)\n",
    "    omy_env.step_env()\n",
    "    # if omy_env.env.loop_every(HZ = 1):\n",
    "    #     omy_env.agument_object_random_color()\n",
    "    if omy_env.env.loop_every(HZ=20):\n",
    "        # Get the action from dataset\n",
    "        data = next(iter_dataloader)\n",
    "        obj_pose = data['obj_pose'][0].numpy()\n",
    "        obj_names = data['obj_names'][0]\n",
    "        obj_names = obj_names.split(',')\n",
    "        recp_q_states = data['obj_q_states'][0].numpy()\n",
    "        recp_q_names = data['obj_q_names'][0]\n",
    "        recp_q_names = recp_q_names.split(',')\n",
    "        omy_env.set_object_pose(obj_pose, obj_names, recp_q_states, recp_q_names)\n",
    "        language_instruction = data['task'][0]\n",
    "        # Get the action from dataset\n",
    "        action = data['action'].numpy()\n",
    "        # print(action.shape)\n",
    "        img = data['image'][0].numpy()*255\n",
    "        img =  np.transpose(img, (1,2,0))\n",
    "        if save_flag:\n",
    "            clips.append(img.astype(np.uint8))\n",
    "            actions.append(action[0])\n",
    "        # print(action.shape)\n",
    "        # obs = PnPEnv.step(state[0])\n",
    "        # Visualize the image from dataset to rgb_overlay\n",
    "        omy_env.rgb_agent = data['image'][0].numpy()*255\n",
    "        omy_env.rgb_ego = data['wrist_image'][0].numpy()*255\n",
    "        omy_env.rgb_agent = omy_env.rgb_agent.astype(np.uint8)\n",
    "        omy_env.rgb_ego = omy_env.rgb_ego.astype(np.uint8)\n",
    "        # 3 256 256 -> 256 256 3\n",
    "        omy_env.rgb_agent = np.transpose(omy_env.rgb_agent, (1,2,0))\n",
    "        omy_env.rgb_ego = np.transpose(omy_env.rgb_ego, (1,2,0))\n",
    "        omy_env.rgb_side = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "        omy_env.render(language_instruction)\n",
    "        step += 1\n",
    "        omy_env.step(action[0])\n",
    "        if step == len(episode_sampler):\n",
    "            # start from the beginning\n",
    "            iter_dataloader = iter(dataloader)\n",
    "            # omy_env.reset()\n",
    "            step = 0\n",
    "        if step == 0:\n",
    "            omy_env.env.reset()\n",
    "            omy_env.reset()\n",
    "            save_flag = False\n",
    "    omy_env.env.sync_sim_wall_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498361f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed79f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
